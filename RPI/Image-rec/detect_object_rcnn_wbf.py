# USAGE
# python detect_object_rcnn.py --image images/raccoon_01.jpg

# import the necessary packages
from pyimagesearch.nms import non_max_suppression
from pyimagesearch.wbf import *
from pyimagesearch import config
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import numpy as np
import argparse
import imutils
import pickle
import cv2

# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", required=True,
	help="path to input image")
args = vars(ap.parse_args())

# load the our fine-tuned model and label binarizer from disk
print("[INFO] loading model and label binarizer...")
model = load_model(config.MODEL_PATH)
lb = pickle.loads(open(config.ENCODER_PATH, "rb").read())

# load the input image from disk
image = cv2.imread(args["image"])
image = imutils.resize(image, width=500)

# run selective search on the image to generate bounding box proposal regions
print("[INFO] running selective search...")
ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
ss.setBaseImage(image)
ss.switchToSelectiveSearchFast()
rects = ss.process()

# initialize the list of region proposals that we'll be classifying
# along with their associated bounding boxes
proposals = []
boxes = []

# loop over the region proposal bounding box coordinates generated by
# running selective search
for (x, y, w, h) in rects[:config.MAX_PROPOSALS_INFER]:
	# extract the region from the input image, convert it from BGR to
	# RGB channel ordering, and then resize it to the required input
	# dimensions of our trained CNN
	roi = image[y:y + h, x:x + w]
	roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
	roi = cv2.resize(roi, config.INPUT_DIMS,
		interpolation=cv2.INTER_CUBIC)
	# further preprocess by the ROI
	roi = img_to_array(roi)
	roi = preprocess_input(roi)

	# update our proposals and bounding boxes lists
	proposals.append(roi)
	boxes.append((x, y, x + w, y + h))
    
    
# convert the proposals and bounding boxes into NumPy arrays
proposals = np.array(proposals, dtype="float32")
boxes = np.array(boxes, dtype="float32")
print("[INFO] proposal shape: {}".format(proposals.shape))

# classify each of the proposal ROIs using fine-tuned model
print("[INFO] classifying proposals...")
proba = model.predict(proposals)

# find the index of all predictions that are positive for the classes
print("[INFO] applying NMS...")
idxs = np.where(proba[:,:15]>config.MIN_PROBA)[0]

# use the indexes to extract all bounding boxes and associated class
# label probabilities associated with the class
boxes = boxes[idxs]
proba = proba[idxs][:, :15]

for i in range(len(boxes)):
	boxes[i][0]=boxes[i][0]/image.shape[1]
	boxes[i][1]=boxes[i][1]/image.shape[0]
	boxes[i][2]=boxes[i][2]/image.shape[1]
	boxes[i][3]=boxes[i][3]/image.shape[0]
labels = [0]*len(boxes)
for i in range(len(boxes)):
	for j in range(15):
		if proba[i][j]>config.MIN_PROBA:
			labels[i]=j+1
scores = [0]*len(boxes)
for i in range(len(boxes)):
	for j in range(15):
		if proba[i][j]>config.MIN_PROBA:
			if proba[i][j] > scores[i]:
				scores[i] = proba[i][j]
boxes_list = [boxes]
scores_list = [scores]
labels_list = [labels]

boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list)
for i in range(len(boxes)):
	boxes[i][0]=boxes[i][0]*image.shape[1]
	boxes[i][1]=boxes[i][1]*image.shape[0]
	boxes[i][2]=boxes[i][2]*image.shape[1]
	boxes[i][3]=boxes[i][3]*image.shape[0]
boxes = np.array(boxes, dtype="int32")
for i in range(len(boxes)):
	# draw the bounding box, label, and probability on the image
	(startX, startY, endX, endY) = boxes[i]
	cv2.rectangle(image, (startX, startY), (endX, endY),
		(0, 255, 0), 2)
	y = startY - 10 if startY - 10 > 10 else startY + 10
	text = str(labels[i])
	cv2.putText(image, text, (startX, y),
		cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)

# show the output image
# cv2.imshow("Image Rec", image)
# cv2.waitKey(0)

# save output image
filename = args["image"]
filename = filename[:filename.rfind(".")] + "_output" + filename[filename.rfind("."):]
cv2.imwrite(filename, image)